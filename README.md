# EagleAndes

游늵 Codefest Ad Astra 2023
<h1>Libreria - Reto 1 - Indetificaci칩n de objetos de inter칠s en videos</h1>

<h3>Instrucciones para correr la librer칤a de python:</h3>
<ul>
  <li>Clonar el repositorio en la carpeta de su preferencia.</li>
  <li>Abrir el proyecto en el editor de preferencia (recomendado <b>Visual Studio Code</b>).</li>
  <li>Abrir la consola e ingresar el comando <code>pip3 install . o pip install .</code> (dependiendo del sistema operativo) para instalar las dependencias asociadas a los recursos empleados definidos en el archivo <code>setup.py</code>.
  <li>Una vez descargado las dependencias necesarias crear un archivo py en la cual se importe la libreria y las funciones requeridas que se quiere aceder. A continuaci칩n, se muestra un ejemplo correspondientemente:
    <ul>
      <li><code>from EagleAndes import detect_objects_in_video</code><br><code>detect_objects_in_video('./video_path', './output_path', cantidad_fotogramas)</code>
      </li>
    </ul>
  </li>
  <li> Esta funci칩n recibe como par치metros de entrada el video a analizar, la ruta donde se va a almacenar el archivo de salida, y la cantidad de fotogramas que quiere analizar. La funci칩n halla la cantidad inicial de fotogramas del video ingresado por par치metro, estos fotogramas se guardan como im치genes y se realizan dos labores principales, la primera es el calculo de coordenadas por medio del an치lisis de texto de la imagen, y la segunda es la segmentaci칩n de este para ver si identifica alg칰n tipo de construcci칩n, veh칤culo o v칤a en el fotograma. Los resultados del an치lisis de coordenadas se almacenana en un .csv, adem치s, si se llega a encontrar alg칰n tipo de objeto durante la segmentaci칩n, la imagen de este fotograma segmentado se almacenar치 en una carpeta.
  </li>
</ul>

<h3>Desarrollo del reto 1:</h3>

<ol>
  <li>En primer lugar, de los videos que pose칤amos, se obtuvieron los fotogramas cada 300 fotogramas y se segmentaron a mano para poder identificar viviendas, vehiculos, v칤as, otros.
</li>
  <li>En segundo lugar, despu칠s de segmentar estas im치genes, se realiz칩 un c칩digo para poder generar una imagen segmentada que pueda ser entendida por la rede nueronal de arquitectura UNET. De esta manera, se entren칩 una red neuronal con esta arquitectura para obtener un modelo que pudiera segmentar.
</li>
  <li> En tercer lugar, se guard칩 este modelo para ser utilizado posteriormente en la soluci칩n final.
  </li>
  <li> Para el an치lisis de coordenadas en las im치genes, se utiliz칩 un modelo preentranado de texto que permit칤a obtener de manera precisa y sencilla el texto que conten칤an los fotogramas.
  </li>
  <li> Por 칰ltimo, se unific칩 tanto el modelo como el analizador de textos en im치gentes en la librer칤a para resolver el reto 1.
  </li>
</ol>

<h1>Libreria - Reto 2 - Procesamiento de lenguage (Clasificaci칩n y NER)</h1>

<h3>Instrucciones para correr la librer칤a de python:</h3>
<ul>
  <li>Clonar el repositorio en la carpeta de su preferencia.</li>
  <li>Abrir el proyecto en el editor de preferencia (recomendado <b>Visual Studio Code</b>).</li>
  <li>Abrir la consola e ingresar el comando <code>pip3 install . o pip install .</code> (dependiendo del sistema operativo) para instalar las dependencias asociadas a los recursos empleados definidos en el archivo <code>setup.py</code>. Asimismo, ingresar el comando para instalar el modelo para el manejo de NER con <code>python -m spacy download es_core_news_md o python3 -m spacy download es_core_news_md</code> dependiendo del sistema operativo.</li>
  <li>Una vez descargado las dependencias necesarias crear un archivo py en la cual se importe la libreria y las funciones requeridas que se quiere aceder. A continuaci칩n, se muestra un ejemplo correspondientemente:
    <ul>
      <li><code>from EagleAndes import ner_from_str</code><br><code>ner_from_str('Texto ejemplo', './output.json')</code>
      </li>
    </ul>
  </li>
  <li>Como se especificaba en la gu칤a se desarrollaron tres metodos los cuales retornan json con el clasificaci칩n. del texto en base a las etiquetas y la identificaci칩n de entidades de nombre.
    <ul>
      <li>def ner_from_str(text, output_path)</li>
      <li>def ner_from_file(text_path, output_path)</li>
      <li>def ner_from_url(url, output_path)</li>
    </ul>
  </li>
</ul>

<h3>Desarrollo del reto 2:</h3>

<ol>
  <li>En primer lugar empezamos por el problema de predici칩n de categoria del textos en cuatro categor칤as: MINERIA, CONTAMINACION, DEFORESTACION, NINGUNA para esto empezamos por un proceso de limpieza de datos, clasificaci칩n de textos sin etiquetas en base del contexto para mejorar la precisi칩n de predici칩n a la hora de entrenar el modelo, 
</li>
  <li>En segundo lugar continuamos con el procesamiento de lenguage aplicando NER (Identificaci칩n de entidades con nombre) para esto utilizamos la libreria de SpaCy con el modelo de es_core_news_md que tiene un f1 89.54 lo cual indica un buen porcentaje de precci칩n en base al recall y accurancy. 
</li>
</ol>
