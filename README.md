# EagleAndes

 Codefest Ad Astra 2023

<h1>Instalaci贸n</h1>

<h3>Instalaci贸n en local:</h3>

  <li>Clonar el repositorio en la carpeta de su preferencia <code>git clone https://github.com/JulianP911/EagleAndes.git</code> .</li> 
  <li>Abrir el proyecto en el editor de preferencia (recomendado <b>Visual Studio Code</b>).</li>
  <li>Abrir la consola e ingresar el comando <code>pip3 install . o pip install .</code> (dependiendo del sistema operativo) para instalar las dependencias asociadas a los recursos empleados definidos en el archivo
  
<h3>Instalaci贸n de la librer铆a:</h3>
  <li>Instalar la libreria mediante pip y el repositorio de github <code>pip install git+https://github.com/JulianP911/EagleAndes.git </code>.</li>   

<h1>Reto 1 - Indetificaci贸n de objetos de inter茅s en videos</h1>

<h3>Instrucciones para correr la librer铆a de python:</h3>
  <li>Una vez instalada la liber铆a junto con las dependencias necesarias crear un archivo py en la cual se importe la libreria y las funciones requeridas que se quiere aceder. A continuaci贸n, se muestra un ejemplo correspondientemente:
    <ul>
      <li><code>from EagleAndes import detect_objects_in_video</code><br><code>detect_objects_in_video('./video_path', './output_path')</code>
      </li>
    </ul>
  </li>
  <li> Esta funci贸n recibe como par谩metros de entrada el video a analizar y la ruta donde se va a almacenar el archivo de salida. (...)
  </li>
</ul>

<h3>Desarrollo del reto 1:</h3>

<ol>
  <li>En primer lugar, de los videos que pose铆amos, se obtuvieron los fotogramas cada 1 segundo. De estos fotogramas se hizo una definici贸n de cuadros delimitadores para la detecci贸n de objetos de inter茅s (construcci贸n, v铆a, veh铆culo, otros). Al rededor de 1.200 im谩genes y 2500 objetos detectados fueron definidos. De esta manera pudimos asegurar una cantidad suficiente de datos para generar un modelo robusto que cumpla con los requerimientos del reto.</li>
  
  <li>Las im谩genes fueron utilizadas como insumo para entrenar al modelo de detecci贸n de objetos <a href="https://github.com/ultralytics/ultralytics.git">YOLOv8</a>. Inicialmente se carg贸 un modelo preentrenado y se realiz贸 un reentrenamiento del modelo para acoplarlo a la detecci贸n de objetos de inter茅s. Se realizaron 150 iteraciones durante el entrenamiento y el modelo resultante fue probado con 153 im谩genes de validaci贸n. Las m茅tricas resultantes indican que el modelo tiene una alta precisi贸n al detectar y localizar los objetos de inter茅s en la imagen.</li> 
  <br>
  
  <table>
  <tr>
    <th>Class</th>
    <th>Images</th>
    <th>Instances</th>
    <th>Box(P)</th>
  </tr>
  <tr>
    <td>all</td>
    <td>153</td>
    <td>496</td>
    <td>0.952</td>
  </tr>
  <tr>
    <td>VEHICULO</td>
    <td>153</td>
    <td>59</td>
    <td>0.959</td>
  </tr>
  <tr>
    <td>CONSTRUCCION</td>
    <td>153</td>
    <td>250</td>
    <td>0.981</td>
  </tr>
  <tr>
    <td>VIA</td>
    <td>153</td>
    <td>3</td>
    <td>0.904</td>
  </tr>
  <tr>
    <td>OTROS</td>
    <td>153</td>
    <td>184</td>
    <td>0.963</td>
  </tr>
</table>

  <li>Para el an谩lisis de coordenadas en las im谩genes, se utiliz贸 el modelo preentrenado de texto <a href="https://www.jaided.ai/easyocr/install/">EasyOCR</a> que permit铆a obtener de manera precisa y sencilla el texto que conten铆an los fotogramas. Cabe resaltar que para lograr un mejor reconocimiento de las coordenadas se hizo un preprocesamiento de las im谩genes que permiti贸 resaltar las car谩cteristicas de los textos presentes en ellas.</li>
  <li>Por 煤ltimo, tanto el modelo como el analizador de textos en im谩genes fueron unificados en la librer铆a para resolver el reto 1.</li>
</ol>

<h1>Libreria - Reto 2 - Procesamiento de lenguage (Clasificaci贸n y NER)</h1>

<h3>Instrucciones para correr la librer铆a de python:</h3>
<ul>
  <li>Clonar el repositorio en la carpeta de su preferencia.</li>
  <li>Abrir el proyecto en el editor de preferencia (recomendado <b>Visual Studio Code</b>).</li>
  <li>Abrir la consola e ingresar el comando <code>pip3 install . o pip install .</code> (dependiendo del sistema operativo) para instalar las dependencias asociadas a los recursos empleados definidos en el archivo <code>setup.py</code>. Asimismo, ingresar el comando para instalar el modelo para el manejo de NER con <code>python -m spacy download es_core_news_md o python3 -m spacy download es_core_news_md</code> dependiendo del sistema operativo.</li>
  <li>Una vez descargado las dependencias necesarias crear un archivo py en la cual se importe la libreria y las funciones requeridas que se quiere aceder. A continuaci贸n, se muestra un ejemplo correspondientemente:
    <ul>
      <li><code>from EagleAndes import ner_from_str</code><br><code>ner_from_str('Texto ejemplo', './output.json')</code>
      </li>
    </ul>
  </li>
  <li>Como se especificaba en la gu铆a se desarrollaron tres metodos los cuales retornan json con el clasificaci贸n. del texto en base a las etiquetas y la identificaci贸n de entidades de nombre.
    <ul>
      <li>def ner_from_str(text, output_path)</li>
      <li>def ner_from_file(text_path, output_path)</li>
      <li>def ner_from_url(url, output_path)</li>
    </ul>
  </li>
</ul>

<h3>Desarrollo del reto 2:</h3>

<ol>
  <li>En primer lugar empezamos por el problema de predici贸n de categoria del textos en cuatro categor铆as: MINERIA, CONTAMINACION, DEFORESTACION, NINGUNA para esto empezamos por un proceso de limpieza de datos, re-clasificaci贸n de textos que ten铆an etiquetas distintas a las que estaban establecidas para la soluci贸n en base del contexto para mejorar la precisi贸n de predici贸n a la hora de entrenar el modelo, que en este caso nos centramos en un RandomForestClassifier que fue el que mejor nos proporcion贸 resultados por medio de b煤squeda de hiperpar谩metros con un accuracy con los datos de entrenamiento del 99% y un accuracy con los datos de test de un 84%.
</li>
  <li>Un punto intermedio entre el etiquetado de datos y el modelado de un RandomForest fue el preprocesamiento , en el cu谩l se realiz贸 todo los tipos de procesos necesarios de limpieza para un modelo lo m谩s 贸ptimo posible cuando se trata de texto. Se realizaron procesos de convertir todos los car谩cteres a min铆sculas, convertir a lenguaje natural los n煤meros que aparecen en el texto, eliminar la puntuaci贸n de las palabras, eliminar los car谩cteres ASCII, eliminar palabras que no son relevantes en el contexto del problema como por ejemplo art铆culos personales, se aplic贸 un proceso de lematizaci贸n de las palabras  y finalmente se listaron las palabras de manera tokenizada. Todo lo anterior para poder tener un modelo de RandomForest de la mejor manera construida.
</li> 
  <li>En tercer lugar, continuamos con el procesamiento de lenguage aplicando NER (Identificaci贸n de entidades con nombre) para esto utilizamos la libreria de SpaCy con el modelo de es_core_news_md que tiene un f1 89.54 lo cual indica un buen porcentaje de precci贸n en base al recall y accuracy para 4 de las 5 clases que se ped铆an obtener una posible clasificaci贸n. 
</li>
  
 <li>Finalmente, para la identificaci贸n de fechas se cre贸 una f贸rmula regex para poder identificar este tipo de entidades que tienen much铆simas tipo de variables posibles.
</li>
</ol>
