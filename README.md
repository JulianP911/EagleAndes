# EagleAndes

游늵 Codefest Ad Astra 2023

<h1>Instalaci칩n</h1>

<h3>Instalaci칩n en local:</h3>
<ul>
  <li>Clonar el repositorio en la carpeta de su preferencia <code>git clone https://github.com/JulianP911/EagleAndes.git</code> .</li> 
  <li>Abrir el proyecto en el editor de preferencia (recomendado <b>Visual Studio Code</b>).</li>
  <li>Abrir la consola e ingresar el comando <code>pip3 install . o pip install .</code> (dependiendo del sistema operativo) para instalar las dependencias asociadas a los recursos empleados definidos en el archivo
</ul>

<h3>Instalaci칩n de la librer칤a:</h3>
<ul>
  <li>Instalar la libreria mediante pip y el repositorio de github <code>pip install git+https://github.com/JulianP911/EagleAndes.git </code>.</li>   
</ul>

<h1>Reto 1 - Indetificaci칩n de objetos de inter칠s en videos</h1>

<h3>Instrucciones para correr la librer칤a de python:</h3>
<ul>
  <li>Una vez instalada la liber칤a junto con las dependencias necesarias crear un archivo py en la cual se importe la libreria y las funciones requeridas que se quiere aceder. A continuaci칩n, se muestra un ejemplo correspondientemente:
    <ul>
      <li><code>from EagleAndes import detect_objects_in_video</code><br><code>detect_objects_in_video('./video_path', './output_path')</code>
      </li>
    </ul>
  </li>
  <li> Esta funci칩n recibe como par치metros de entrada el video a analizar y la ruta donde se va a almacenar el archivo de salida. (...)
  </li>
</ul>

<h3>Desarrollo del reto 1:</h3>

<ol>
  <li>En primer lugar, de los videos que pose칤amos, se obtuvieron los fotogramas cada 1 segundo. De estos fotogramas se hizo una definici칩n de cuadros delimitadores para la detecci칩n de objetos de inter칠s (construcci칩n, v칤a, veh칤culo, otros). Al rededor de 1.200 im치genes y 2500 objetos detectados fueron definidos. De esta manera pudimos asegurar una cantidad suficiente de datos para generar un modelo robusto que cumpla con los requerimientos del reto.</li>
  
  <li>Las im치genes fueron utilizadas como insumo para entrenar al modelo de detecci칩n de objetos <a href="https://github.com/ultralytics/ultralytics.git">YOLOv8</a>. Inicialmente se carg칩 un modelo preentrenado y se realiz칩 un reentrenamiento del modelo para acoplarlo a la detecci칩n de objetos de inter칠s. Se realizaron 150 iteraciones durante el entrenamiento y el modelo resultante fue probado con 153 im치genes de validaci칩n. Las m칠tricas resultantes indican que el modelo tiene una alta precisi칩n al detectar y localizar los objetos de inter칠s en la imagen.</li> 
  <br>
  
  <table>
  <tr>
    <th>Class</th>
    <th>Images</th>
    <th>Instances</th>
    <th>Box(P)</th>
  </tr>
  <tr>
    <td>all</td>
    <td>153</td>
    <td>496</td>
    <td>0.952</td>
  </tr>
  <tr>
    <td>VEHICULO</td>
    <td>153</td>
    <td>59</td>
    <td>0.959</td>
  </tr>
  <tr>
    <td>CONSTRUCCION</td>
    <td>153</td>
    <td>250</td>
    <td>0.981</td>
  </tr>
  <tr>
    <td>VIA</td>
    <td>153</td>
    <td>3</td>
    <td>0.904</td>
  </tr>
  <tr>
    <td>OTROS</td>
    <td>153</td>
    <td>184</td>
    <td>0.963</td>
  </tr>
</table>

  <li>Para el an치lisis de coordenadas en las im치genes, se utiliz칩 el modelo preentrenado de texto <a href="https://www.jaided.ai/easyocr/install/">EasyOCR</a> que permit칤a obtener de manera precisa y sencilla el texto que conten칤an los fotogramas. Cabe resaltar que para lograr un mejor reconocimiento de las coordenadas se hizo un preprocesamiento de las im치genes que permiti칩 resaltar las car치cteristicas de los textos presentes en ellas.</li>
  <li>Por 칰ltimo, tanto el modelo como el analizador de textos en im치genes fueron unificados en la librer칤a para resolver el reto 1.</li>
</ol>

<h1>Libreria - Reto 2 - Procesamiento de lenguage (Clasificaci칩n y NER)</h1>

<h3>Instrucciones para correr la librer칤a de python:</h3>
<ul>
<li>Una vez instalada la liber칤a junto con las dependencias necesarias crear un archivo py en la cual se importe la libreria y las funciones requeridas que se quiere aceder. A continuaci칩n, se muestra un ejemplo correspondientemente:
    <ul>
      <li><code>from EagleAndes import ner_from_str</code><br><code>ner_from_str('Texto ejemplo', './output.json')</code>
      </li>
    </ul>
  </li>
  <li>Como se especificaba en la gu칤a se desarrollaron tres metodos los cuales retornan json con el clasificaci칩n. del texto en base a las etiquetas y la identificaci칩n de entidades de nombre.
    <ul>
      <li>def ner_from_str(text, output_path)</li>
      <li>def ner_from_file(text_path, output_path)</li>
      <li>def ner_from_url(url, output_path)</li>
    </ul>
  </li>
</ul>

<h3>Desarrollo del reto 2:</h3>

<ol>
  <li>En primer lugar empezamos por el problema de predici칩n de categoria del textos en cuatro categor칤as: MINERIA, CONTAMINACION, DEFORESTACION, NINGUNA para esto empezamos por un proceso de limpieza de datos, re-clasificaci칩n de textos que ten칤an etiquetas distintas a las que estaban establecidas para la soluci칩n en base del contexto para mejorar la precisi칩n de predici칩n a la hora de entrenar el modelo, que en este caso nos centramos en un RandomForestClassifier que fue el que mejor nos proporcion칩 resultados por medio de b칰squeda de hiperpar치metros con un accuracy con los datos de entrenamiento del 99% y un accuracy con los datos de test de un 84%.
</li>
  <li>Un punto intermedio entre el etiquetado de datos y el modelado de un RandomForest fue el preprocesamiento , en el cu치l se realiz칩 todo los tipos de procesos necesarios de limpieza para un modelo lo m치s 칩ptimo posible cuando se trata de texto. Se realizaron procesos de convertir todos los car치cteres a min칤sculas, convertir a lenguaje natural los n칰meros que aparecen en el texto, eliminar la puntuaci칩n de las palabras, eliminar los car치cteres ASCII, eliminar palabras que no son relevantes en el contexto del problema como por ejemplo art칤culos personales, se aplic칩 un proceso de lematizaci칩n de las palabras  y finalmente se listaron las palabras de manera tokenizada. Todo lo anterior para poder tener un modelo de RandomForest de la mejor manera construida.
</li> 
  <li>En tercer lugar, continuamos con el procesamiento de lenguage aplicando NER (Identificaci칩n de entidades con nombre) para esto utilizamos la libreria de SpaCy con el modelo de es_core_news_md que tiene un f1 89.54 lo cual indica un buen porcentaje de precci칩n en base al recall y accuracy para 4 de las 5 clases que se ped칤an obtener una posible clasificaci칩n. 
</li>
 <li>Por 칰ltimo, tanto el modelo de clasificaci칩n de impacto como el modelo NER fueron unificados en la librer칤a para resolver el reto 2.
</li>
</ol>
